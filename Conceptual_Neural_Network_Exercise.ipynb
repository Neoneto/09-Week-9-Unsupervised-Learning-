{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conceptual Neural Network Exercise",
      "provenance": [],
      "authorship_tag": "ABX9TyMD9qSJRhCb3Hg4ipZPKLDm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neoneto/09-Week-9-Unsupervised-Learning-/blob/main/Conceptual_Neural_Network_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conceptual Neural Network Exercise\n",
        "Submitted by Kenneth Alaba"
      ],
      "metadata": {
        "id": "buFukSjZY6cZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Part 1\n",
        "\n",
        "You will use the [Tensorflow Playground](https://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.01&regularizationRate=0&noise=0&networkShape=1&seed=0.38153&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) to answer the following questions about neural networks. The goal of this exercise is to better understand how neural networks work at a conceptual level.\n",
        "\n",
        "1. Double check that [your playground](https://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.01&regularizationRate=0&noise=0&networkShape=1&seed=0.38153&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) is set up like the image below with 2 features, 1 hidden layer with 1 neuron, and the circle data. You should have a learning rate of 0.01, a Linear activation function, and no regularization.\n",
        "\n",
        "![](https://s3.amazonaws.com/General_V88/boomyeah2015/codingdojo/curriculum/content/chapter/Screen_Shot_2021-01-29_at_11.37.12_AM.png)\n",
        "\n",
        "Press the \"play\" button to train the network.\n",
        "\n",
        "1. Run the network. What do you notice?\n",
        "\n",
        "> The output layer does not represent the information of the data. Additionally, the hidden layers and the weights barely learn even after a few hundred epochs. This implies that the model is inappropriate for the data.\n",
        "\n",
        "2. Now, increase the number of neurons in the hidden layer and try changing the activation function to something other than \"Linear.\" Can you model the data now? How many neurons and what activation function allows you to effectively model the data?\n",
        "\n",
        "> Using 3 neurons with ReLU activation achieve a decent result with the least number of neurons. Using 4 neurons increases the performance with both the test and train loss decaying exponentially and achieving an asymptotic value of around 0.01, for both train and test, with just a few hundred epochs.\n",
        "\n",
        "3. Feel free to add more neurons, layers, or change anything you would like - can you model the data so that the testing loss is 0.01 or less? What is the smallest number of neurons and layers you can use that gives a test loss of 0.01 or less?\n",
        "\n",
        "> From the visualization, we can see that the data points are divided in an almost circular manner. Using non linear features such as $$X_1^2,\\; X_2^2,\\; \\sin(X_1)$$ with at least 2 hidden layers each with at least 2 neurons can achieve both a test and training loss of 0.001 in less than 300 epochs.\n",
        "Using the two linear inputs, a minimum of 2 Hidden layers each with 3 neurons is required to reach a loss of 0.01. \n",
        "\n",
        "4. Play around with the learning rate. What do you notice? Based on this, what do you think the learning rate is?\n",
        "\n",
        "> The learning rate corresponds to the step size in the output loss. Since we want to minimize the loss, using a small step might be good but it will take time specially for larger data sets while using higher rate is faster but might miss the minimum loss and cause the model to oscillate around the minimum point and display a diverging behavior.\n"
      ],
      "metadata": {
        "id": "hSNwTnJdY-KX"
      }
    }
  ]
}